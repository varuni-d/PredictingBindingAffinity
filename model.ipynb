{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['LinearRegression','DecisionTreeRegressor','RandomForestRegressor']\n",
    "score_table = pd.DataFrame(index = models, columns= ['rmse_train','rmse_test','mae_train','mae_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the performance for both training and test datasets\n",
    "def plot_result(model_name,y_train, train_pred, y_test, test_pred):\n",
    "    \n",
    "    # compute the performance\n",
    "    r2_train = r2_score(y_train, train_pred)\n",
    "    r2_test = r2_score(y_test, test_pred)\n",
    "\n",
    "    mae_train = MAE(y_train, train_pred)\n",
    "    mse_train = MSE(y_train, train_pred)\n",
    "    rmse_train=np.sqrt(mse_train)\n",
    "\n",
    "    mae_test = MAE(y_test, test_pred)\n",
    "    mse_test = MSE(y_test, test_pred)   \n",
    "    rmse_test=np.sqrt(mse_test)\n",
    "\n",
    "#    score_table.loc[model_name,:] = r2_train, r2_test, mae_train, mae_test\n",
    "    score_table.loc[model_name,:] = rmse_train, rmse_test, mae_train, mae_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear Regression model\n",
    "\n",
    "def linear_regression(X_train, y_train, X_test, y_test):\n",
    "\n",
    "  #  lr_model = Pipeline([('scaler', MinMaxScaler()),('lr_model',LinearRegression())])\n",
    "  \n",
    "    lr_model = Pipeline([('scaler', StandardScaler()),('lr_model',LinearRegression())])\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    #predict on training set    \n",
    "    train_pred = lr_model.predict(X_train)\n",
    "    #repeat on test set \n",
    "    test_pred = lr_model.predict(X_test)\n",
    "    \n",
    "    plot_result('LinearRegression', y_train, train_pred, y_test, test_pred)  \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisiontree(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    dt_model = Pipeline([('scaler', StandardScaler()),('dt_model',DecisionTreeRegressor(random_state=1))])\n",
    "    #Hyper-parameter tuning and 5-fold cross-validation\n",
    "    params_dt = {'dt_model__max_leaf_nodes': [150, 250, 300],'dt_model__max_features': ['log2', 'auto', 'sqrt'],'dt_model__min_samples_leaf': [10, 30, 50]}\n",
    "    grid_dt=GridSearchCV(estimator=dt_model, param_grid=params_dt, scoring='neg_mean_absolute_error', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "    grid_dt.fit(X_train, y_train)\n",
    "\n",
    "    #Predict and convert back to real\n",
    "    train_pred = grid_dt.predict(X_train)\n",
    "\n",
    "    #repeat on test set \n",
    "    test_pred = grid_dt.predict(X_test)\n",
    "\n",
    "    plot_result('DecisionTreeRegressor', y_train, train_pred, y_test, test_pred)\n",
    "\n",
    "    #Extract the best estimators\n",
    "    best_hyperparameters=grid_dt.best_params_\n",
    "    print('Best hyperparameters:',best_hyperparameters)\n",
    "    best_model = grid_dt.best_estimator_\n",
    "    print('Best model:',best_model)\n",
    "    print('Corresponding score:', grid_dt.best_score_)\n",
    "    \n",
    "    return test_pred   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest(X_train, y_train, X_test, y_test):\n",
    "    #Instantiate model\n",
    "    rf_model = Pipeline([('scaler', StandardScaler()),('rf_model',RandomForestRegressor(random_state=1))])\n",
    "#    rf_model = RandomForestRegressor(random_state=1)\n",
    "    #Hyper-parameter tuning and 5-fold cross-validation\n",
    "    params_rf = {'rf_model__n_estimators': [100, 200, 300],'rf_model__max_features': ['log2', 'auto', 'sqrt'],'rf_model__min_samples_leaf': [10, 30, 50]}\n",
    "    grid_rf=GridSearchCV(estimator=rf_model, param_grid=params_rf, scoring='neg_mean_absolute_error', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "    #Fit\n",
    "    grid_rf.fit(X_train, y_train)\n",
    "\n",
    "    #Predict and convert back to real\n",
    "    train_pred = grid_rf.predict(X_train)\n",
    "\n",
    "    #repeat on test set \n",
    "    test_pred = grid_rf.predict(X_test)\n",
    "\n",
    "    plot_result('RandomForestRegressor', y_train, train_pred, y_test, test_pred)\n",
    "\n",
    "    #Extract the best estimators\n",
    "    best_hyperparameters=grid_rf.best_params_\n",
    "    print('Best hyperparameters:',best_hyperparameters)\n",
    "    best_model = grid_rf.best_estimator_\n",
    "    print('Best model:',best_model)\n",
    "    print('Corresponding score:', grid_rf.best_score_)\n",
    "    \n",
    "    filename = 'randomforest_model.sav'\n",
    "    pickle.dump(grid_rf, open(filename, 'wb'))\n",
    "    \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientboosting(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Instantiate gb\n",
    "    gb_model = Pipeline([('scaler', StandardScaler()),('gb_model',GradientBoostingRegressor(random_state=1))])\n",
    "\n",
    "    #Hyper-parameter tuning and 5-fold cross-validation\n",
    "    params_gb = {'gb_model__n_estimators': [100, 500, 1000],'gb_model__max_depth': [5,10,20],'gb_model__learning_rate': [0.01,0.1,1.0]}\n",
    "    grid_gb=GridSearchCV(estimator=gb_model, param_grid=params_gb, scoring='neg_mean_absolute_error', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "    grid_gb.fit(X_train, y_train)\n",
    "\n",
    "    #Predict and convert back to real\n",
    "    train_pred = grid_gb.predict(X_train)\n",
    "    \n",
    "    #repeat on test set \n",
    "    test_pred = grid_gb.predict(X_test)\n",
    "\n",
    "    plot_result('GradientBoostingRegressor', y_train, train_pred, y_test, test_pred)\n",
    "\n",
    "    #Extract the best estimators\n",
    "    best_hyperparameters=grid_gb.best_params_\n",
    "    print('Best hyperparameters:',best_hyperparameters)\n",
    "    best_model = grid_gb.best_estimator_\n",
    "    print('Best model:',best_model)\n",
    "    print('Corresponding score:', grid_gb.best_score_)\n",
    "    \n",
    "    filename = 'gradientboost_model.sav'\n",
    "    pickle.dump(grid_gb, open(filename, 'wb'))\n",
    "    \n",
    "    return test_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
