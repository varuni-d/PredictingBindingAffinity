{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - the MySageMakerInstance is in the us-west-2 region. You will use the 433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest container for your SageMaker endpoint.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np                                \n",
    "import pandas as pd                               \n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "from sagemaker.predictor import csv_serializer   \n",
    "\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'sagemaker/DEMO-xgboost-dm'\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'} # each region has its XGBoost container\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" + containers[my_region] + \" container for your SageMaker endpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket sagemaker-us-west-2-929878552275\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "print('Using bucket ' + bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 error:  An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'drugs-public' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if  my_region == 'us-east-1':\n",
    "      s3.create_bucket(Bucket=bucket_name)\n",
    "    else: \n",
    "      s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={ 'LocationConstraint': my_region })\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket='drugs-public'\n",
    "data_key = 'df_ligand_protein.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "df_3d=pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key = 'morgan_matrix_generated_ligandprotein.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "morgan_matrix_df=pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52283 entries, 0 to 52282\n",
      "Data columns (total 3 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   bindingdb_target_chain__sequence  52283 non-null  object \n",
      " 1   ligand_smiles                     52283 non-null  object \n",
      " 2   bindingaffinity                   52283 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_3d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smiles=df_3d['ligand_smiles']\n",
    "df_protein=df_3d['bindingdb_target_chain__sequence']\n",
    "df_ba=df_3d['bindingaffinity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dindex=[1460,4119,4120,4121,4122,4123,4124,4193,4194,4195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_protein.drop(df_protein.index[dindex], axis=0, inplace=True)\n",
    "df_ba.drop(df_ba.index[dindex], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ligand_features(morgan_matrix_df,df_ba,test_size=0.2):\n",
    "    print('Generating ligand features...')\n",
    "    LX_train,LX_test,Ly_train,Ly_test=train_test_split(morgan_matrix_df,df_ba,test_size=0.2,random_state=42,shuffle=False)\n",
    "    #Dimensionality reduction\n",
    "    pca=PCA(.90)\n",
    "    pca.fit(LX_train)\n",
    "    print('Ligand features after PCA:',pca.n_components_)\n",
    "    LX_train = pca.transform(LX_train)\n",
    "    LX_test = pca.transform(LX_test)\n",
    "    print('Ligand features complete!')\n",
    "    return LX_train,LX_test,Ly_train,Ly_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protein_features(df_protein, df_ba, test_size = 0.2):\n",
    "    print('Generating protein features...')   \n",
    "    PX_train,PX_test,y_train,y_test = train_test_split(df_protein, df_ba, test_size = 0.2, random_state = 42,shuffle=False)\n",
    "\n",
    "    # Create a Count Vectorizer to gather the unique elements in sequence\n",
    "    vect = CountVectorizer(analyzer = 'char_wb', ngram_range = (4,4))\n",
    "\n",
    "    # Fit and Transform CountVectorizer\n",
    "    vect.fit(PX_train)\n",
    "    PX_train = vect.transform(PX_train)\n",
    "    PX_test = vect.transform(PX_test)\n",
    "    \n",
    "    #Dimensionality reduction\n",
    "    svd = sklearn.decomposition.TruncatedSVD(n_components=50)\n",
    "    PX_train = svd.fit_transform(PX_train)\n",
    "    PX_test = svd.transform(PX_test)\n",
    "\n",
    "    #print('Protein features':vect.get_feature_names()[-20:])\n",
    "    print('Protein features complete!')\n",
    "    return PX_train,PX_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ligand features...\n",
      "Ligand features after PCA: 191\n",
      "Ligand features complete!\n",
      "Generating protein features...\n",
      "Protein features complete!\n"
     ]
    }
   ],
   "source": [
    "test_size=0.2\n",
    "LX_train,LX_test,Ly_train,Ly_test=ligand_features(morgan_matrix_df,df_ba,test_size)\n",
    "PX_train,PX_test,Py_train,Py_test=protein_features(df_protein,df_ba,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41818, 191)\n",
      "(41818, 50)\n",
      "(10455, 191)\n",
      "(10455, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(LX_train.shape),print(PX_train.shape)\n",
    "print(LX_test.shape),print(PX_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PX_train_df = pd.DataFrame(PX_train)\n",
    "LX_train_df = pd.DataFrame(LX_train)\n",
    "\n",
    "PX_test_df = pd.DataFrame(PX_test)\n",
    "LX_test_df = pd.DataFrame(LX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PX_train_df.columns = PX_train_df.columns.map(lambda x: str(x) + '_b')\n",
    "PX_test_df.columns = PX_test_df.columns.map(lambda x: str(x) + '_b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge protein and ligand features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_train=PX_train_df.join(LX_train_df)\n",
    "df_total_test=PX_test_df.join(LX_test_df)\n",
    "\n",
    "y_train=pd.DataFrame(Py_train)\n",
    "y_test=pd.DataFrame(Py_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_train.reset_index(inplace=True,drop=True)\n",
    "df_total_test.reset_index(inplace=True,drop=True)\n",
    "\n",
    "y_train.reset_index(inplace=True,drop=True)\n",
    "y_test.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bindingaffinity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.309804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.366532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10450</th>\n",
       "      <td>8.568636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10451</th>\n",
       "      <td>9.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10452</th>\n",
       "      <td>10.346787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10453</th>\n",
       "      <td>7.769551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10454</th>\n",
       "      <td>7.721246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10455 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bindingaffinity\n",
       "0             7.309804\n",
       "1             7.366532\n",
       "2             5.000000\n",
       "3             5.000000\n",
       "4             5.000000\n",
       "...                ...\n",
       "10450         8.568636\n",
       "10451         9.397940\n",
       "10452        10.346787\n",
       "10453         7.769551\n",
       "10454         7.721246\n",
       "\n",
       "[10455 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/scikit_learn_randomforest/Sklearn_on_SageMaker_end2end.ipynb\n",
    "\n",
    "trainX = pd.DataFrame(df_total_train)\n",
    "trainX['target'] = y_train\n",
    "\n",
    "testX = pd.DataFrame(df_total_test)\n",
    "testX['target'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_b</th>\n",
       "      <th>1_b</th>\n",
       "      <th>2_b</th>\n",
       "      <th>3_b</th>\n",
       "      <th>4_b</th>\n",
       "      <th>5_b</th>\n",
       "      <th>6_b</th>\n",
       "      <th>7_b</th>\n",
       "      <th>8_b</th>\n",
       "      <th>9_b</th>\n",
       "      <th>...</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.208051</td>\n",
       "      <td>0.604058</td>\n",
       "      <td>0.473296</td>\n",
       "      <td>0.289918</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.400958</td>\n",
       "      <td>-1.836151</td>\n",
       "      <td>-0.52466</td>\n",
       "      <td>-0.258139</td>\n",
       "      <td>-0.073828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020933</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.049205</td>\n",
       "      <td>0.018360</td>\n",
       "      <td>0.051950</td>\n",
       "      <td>-0.001727</td>\n",
       "      <td>-0.011288</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.005646</td>\n",
       "      <td>7.309804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.208051</td>\n",
       "      <td>0.604058</td>\n",
       "      <td>0.473296</td>\n",
       "      <td>0.289918</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.400958</td>\n",
       "      <td>-1.836151</td>\n",
       "      <td>-0.52466</td>\n",
       "      <td>-0.258139</td>\n",
       "      <td>-0.073828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029299</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>-0.006265</td>\n",
       "      <td>0.046739</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>0.010059</td>\n",
       "      <td>0.008890</td>\n",
       "      <td>-0.005812</td>\n",
       "      <td>0.014569</td>\n",
       "      <td>7.366532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.208051</td>\n",
       "      <td>0.604058</td>\n",
       "      <td>0.473296</td>\n",
       "      <td>0.289918</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.400958</td>\n",
       "      <td>-1.836151</td>\n",
       "      <td>-0.52466</td>\n",
       "      <td>-0.258139</td>\n",
       "      <td>-0.073828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010844</td>\n",
       "      <td>-0.034868</td>\n",
       "      <td>-0.008864</td>\n",
       "      <td>-0.022088</td>\n",
       "      <td>0.019633</td>\n",
       "      <td>0.027510</td>\n",
       "      <td>-0.009552</td>\n",
       "      <td>0.036593</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.208051</td>\n",
       "      <td>0.604058</td>\n",
       "      <td>0.473296</td>\n",
       "      <td>0.289918</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.400958</td>\n",
       "      <td>-1.836151</td>\n",
       "      <td>-0.52466</td>\n",
       "      <td>-0.258139</td>\n",
       "      <td>-0.073828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007236</td>\n",
       "      <td>-0.043480</td>\n",
       "      <td>-0.020554</td>\n",
       "      <td>0.016175</td>\n",
       "      <td>0.042715</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>0.017251</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.399342</td>\n",
       "      <td>1.521650</td>\n",
       "      <td>1.386567</td>\n",
       "      <td>1.351741</td>\n",
       "      <td>1.845702</td>\n",
       "      <td>0.787432</td>\n",
       "      <td>-4.008339</td>\n",
       "      <td>-0.86938</td>\n",
       "      <td>-0.514733</td>\n",
       "      <td>0.158044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>-0.029880</td>\n",
       "      <td>-0.039547</td>\n",
       "      <td>-0.024458</td>\n",
       "      <td>-0.017620</td>\n",
       "      <td>0.012704</td>\n",
       "      <td>-0.004906</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0_b       1_b       2_b       3_b       4_b       5_b       6_b  \\\n",
       "0  1.208051  0.604058  0.473296  0.289918  0.790123  0.400958 -1.836151   \n",
       "1  1.208051  0.604058  0.473296  0.289918  0.790123  0.400958 -1.836151   \n",
       "2  1.208051  0.604058  0.473296  0.289918  0.790123  0.400958 -1.836151   \n",
       "3  1.208051  0.604058  0.473296  0.289918  0.790123  0.400958 -1.836151   \n",
       "4  2.399342  1.521650  1.386567  1.351741  1.845702  0.787432 -4.008339   \n",
       "\n",
       "       7_b       8_b       9_b  ...       182       183       184       185  \\\n",
       "0 -0.52466 -0.258139 -0.073828  ...  0.020933  0.000002  0.049205  0.018360   \n",
       "1 -0.52466 -0.258139 -0.073828  ...  0.029299  0.006279 -0.006265  0.046739   \n",
       "2 -0.52466 -0.258139 -0.073828  ...  0.010844 -0.034868 -0.008864 -0.022088   \n",
       "3 -0.52466 -0.258139 -0.073828  ... -0.007236 -0.043480 -0.020554  0.016175   \n",
       "4 -0.86938 -0.514733  0.158044  ... -0.004017  0.002042  0.019585 -0.029880   \n",
       "\n",
       "        186       187       188       189       190    target  \n",
       "0  0.051950 -0.001727 -0.011288  0.032895  0.005646  7.309804  \n",
       "1  0.004290  0.010059  0.008890 -0.005812  0.014569  7.366532  \n",
       "2  0.019633  0.027510 -0.009552  0.036593  0.024887  5.000000  \n",
       "3  0.042715  0.004216  0.017176  0.017251  0.010325  5.000000  \n",
       "4 -0.039547 -0.024458 -0.017620  0.012704 -0.004906  5.000000  \n",
       "\n",
       "[5 rows x 242 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.to_csv('train.csv')\n",
    "testX.to_csv('validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testX.isnull().sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "trainpath = sess.upload_data(\n",
    "    path='train.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/sklearncontainer')\n",
    "\n",
    "testpath = sess.upload_data(\n",
    "    path='validation.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/sklearncontainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rf_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rf_script.py\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "\n",
    "# inference functions ---------------\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    print('extracting arguments')\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    # to simplify the demo we don't use all sklearn RandomForest hyperparameters\n",
    "    parser.add_argument('--n-estimators', type=int, default=10)\n",
    "    parser.add_argument('--min-samples-leaf', type=int, default=3)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "    parser.add_argument('--train-file', type=str, default='train.csv')\n",
    "    parser.add_argument('--test-file', type=str, default='validation.csv')\n",
    "#    parser.add_argument('--features', type=str)  # in this script we ask user to explicitly name features\n",
    "#    parser.add_argument('--target', type=str) # in this script we ask user to explicitly name the target\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print('reading data')\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    print('building training and testing datasets')\n",
    "    X_train=train_df.drop('target',axis=1)\n",
    "    y_train=train_df['target']\n",
    "    \n",
    "    X_test=test_df.drop('target',axis=1)\n",
    "    y_test=test_df['target']\n",
    "    \n",
    "#    X_train = train_df[args.features.split()]\n",
    "#    X_test = test_df[args.features.split()]\n",
    "#    y_train = train_df[args.target]\n",
    "#    y_test = test_df[args.target]\n",
    "\n",
    "    # train\n",
    "    print('training model')\n",
    "    model = RandomForestRegressor(n_estimators=args.n_estimators,min_samples_leaf=args.min_samples_leaf,n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "\n",
    "#    rf_model = Pipeline([('scaler', StandardScaler()),('rf_model',RandomForestRegressor(random_state=1))])\n",
    "#    params_rf = {'rf_model__n_estimators': [100, 200, 300],'rf_model__max_features': ['log2', 'auto', 'sqrt'],'rf_model__min_samples_leaf': [10, 30, 50]}\n",
    "#    grid_rf=GridSearchCV(estimator=rf_model, param_grid=params_rf, scoring='neg_mean_absolute_error', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "    #Fit and predict\n",
    "#    grid_rf.fit(X_train, y_train)\n",
    "#    test_pred = grid_rf.predict(X_test)\n",
    "    \n",
    "    mae_test = MAE(y_test, test_pred)\n",
    "    mse_test = MSE(y_test, test_pred)   \n",
    "    rmse_test=np.sqrt(mse_test)\n",
    "    print('MAE:', mae_test)\n",
    "    print('RMSE:',rmse_test)\n",
    "    \n",
    "    # print abs error\n",
    "#    print('validating model')\n",
    "#    abs_err = np.abs(model.predict(X_test) - y_test)\n",
    "#    print(abs_err)\n",
    "\n",
    "    # print couple perf metrics\n",
    " #   for q in [10, 50, 90]:\n",
    " #       print('AE-at-' + str(q) + 'th-percentile: '\n",
    " #             + str(np.percentile(a=abs_err, q=q)))\n",
    "        \n",
    "    # persist model\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    print('model persisted at ' + path)\n",
    "    print(args.min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local training\n",
    "#! python rf_script.py --n-estimators 100 --min-samples-leaf 2 --model-dir ./ --train ./ --test ./ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python SDK training\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = '0.23-1'\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='rf_script.py',\n",
    "    role = get_execution_role(),\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c5.xlarge',\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    base_job_name='rf-scikit',\n",
    " #   metric_definitions=[\n",
    " #       {'Name': 'median-AE',\n",
    " #        'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}],\n",
    "    hyperparameters = {'n-estimators': 100,\n",
    "                       'min-samples-leaf': 3})\n",
    " #                      'features': 'CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT',\n",
    " #                      'target': 'target'})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# launch training job, with asynchronous call\n",
    "sklearn_estimator.fit({'train':trainpath, 'test': testpath}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------"
     ]
    }
   ],
   "source": [
    "# Deploy my estimator to a SageMaker Endpoint and get a Predictor\n",
    "predictor = sklearn_estimator.deploy(instance_type='ml.c5.xlarge',initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Hyperparameter Tuning</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter\n",
    "\n",
    "# Define exploration boundaries\n",
    "hyperparameter_ranges = {\n",
    "    'n-estimators': IntegerParameter(20, 100),\n",
    "    'min-samples-leaf': IntegerParameter(2, 6)}\n",
    "\n",
    "# create Optimizer\n",
    "Optimizer = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator=sklearn_estimator,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    base_tuning_job_name='RF-tuner',\n",
    "    objective_type='Minimize',\n",
    "    objective_metric_name='median-AE',\n",
    "    metric_definitions=[\n",
    "        {'Name': 'median-AE',\n",
    "         'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}],  # extract tracked metric from logs with regexp \n",
    "    max_jobs=20,\n",
    "    max_parallel_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "Optimizer.fit({'train': trainpath, 'test': testpath})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min-samples-leaf</th>\n",
       "      <th>n-estimators</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>RF-tuner-201015-0255-004-98812e35</td>\n",
       "      <td>InProgress</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-10-15 03:02:34+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>RF-tuner-201015-0255-003-7797d702</td>\n",
       "      <td>InProgress</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-10-15 03:02:18+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>RF-tuner-201015-0255-002-9e91c0af</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-10-15 02:57:11+00:00</td>\n",
       "      <td>2020-10-15 03:00:08+00:00</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>RF-tuner-201015-0255-001-06273d53</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-10-15 02:57:02+00:00</td>\n",
       "      <td>2020-10-15 03:00:18+00:00</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min-samples-leaf  n-estimators                    TrainingJobName  \\\n",
       "0               3.0         100.0  RF-tuner-201015-0255-004-98812e35   \n",
       "1               2.0          99.0  RF-tuner-201015-0255-003-7797d702   \n",
       "2               2.0          59.0  RF-tuner-201015-0255-002-9e91c0af   \n",
       "3               4.0          74.0  RF-tuner-201015-0255-001-06273d53   \n",
       "\n",
       "  TrainingJobStatus FinalObjectiveValue         TrainingStartTime  \\\n",
       "0        InProgress                None 2020-10-15 03:02:34+00:00   \n",
       "1        InProgress                None 2020-10-15 03:02:18+00:00   \n",
       "2         Completed                None 2020-10-15 02:57:11+00:00   \n",
       "3         Completed                None 2020-10-15 02:57:02+00:00   \n",
       "\n",
       "            TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "0                       NaT                         NaN  \n",
       "1                       NaT                         NaN  \n",
       "2 2020-10-15 03:00:08+00:00                       177.0  \n",
       "3 2020-10-15 03:00:18+00:00                       196.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "# get tuner results in a df\n",
    "results = Optimizer.analytics().dataframe()\n",
    "while results.empty:\n",
    "    time.sleep(1)\n",
    "    results = Optimizer.analytics().dataframe()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-10-15 02:59:12 Starting - Preparing the instances for training\n",
      "2020-10-15 02:59:12 Downloading - Downloading input data\n",
      "2020-10-15 02:59:12 Training - Training image download completed. Training in progress.\n",
      "2020-10-15 02:59:12 Uploading - Uploading generated training model\n",
      "2020-10-15 02:59:12 Completed - Training job completed\n",
      "Model artifact persisted at s3://sagemaker-us-west-2-929878552275/rf-scikit-2020-10-15-02-52-50-981/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "sklearn_estimator.latest_training_job.wait(logs='None')\n",
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name)['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "print('Model artifact persisted at ' + artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-10-15 02:47:39 Starting - Preparing the instances for training\n",
      "2020-10-15 02:47:39 Downloading - Downloading input data\n",
      "2020-10-15 02:47:39 Training - Training image download completed. Training in progress.\n",
      "2020-10-15 02:47:39 Uploading - Uploading generated training model\n",
      "2020-10-15 02:47:39 Completed - Training job completed\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sm_boto3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a4a45f67a9e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msklearn_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'None'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m artifact = sm_boto3.describe_training_job(\n\u001b[0m\u001b[1;32m      3\u001b[0m     TrainingJobName=sklearn_estimator.latest_training_job.name)['ModelArtifacts']['S3ModelArtifacts']\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model artifact persisted at '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0martifact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sm_boto3' is not defined"
     ]
    }
   ],
   "source": [
    "sklearn_estimator.latest_training_job.wait(logs='None')\n",
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name)['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "print('Model artifact persisted at ' + artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "model = SKLearnModel(\n",
    "    model_data=artifact,\n",
    "    role=get_execution_role(),\n",
    "    entry_point='rf_script.py',\n",
    "    framework_version=FRAMEWORK_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    instance_type='ml.c5.xlarge',\n",
    "    initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter\n",
    "\n",
    "# Define exploration boundaries\n",
    "hyperparameter_ranges = {\n",
    "    'n-estimators': IntegerParameter(20, 100),\n",
    "    'min-samples-leaf': IntegerParameter(2, 6)}\n",
    "\n",
    "# create Optimizer\n",
    "Optimizer = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator=sklearn_estimator,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    base_tuning_job_name='RF-tuner',\n",
    "    objective_type='Minimize',\n",
    "    objective_metric_name='median-AE',\n",
    "    metric_definitions=[\n",
    "        {'Name': 'median-AE',\n",
    "         'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}],  # extract tracked metric from logs with regexp \n",
    "    max_jobs=20,\n",
    "    max_parallel_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=y_train.join(df_total_train)\n",
    "test_data=y_test.join(df_total_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10455 entries, 0 to 10454\n",
      "Columns: 242 entries, bindingaffinity to 190\n",
      "dtypes: float64(242)\n",
      "memory usage: 19.3 MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "xgb = sagemaker.estimator.Estimator(containers[my_region],role, train_instance_count=1, train_instance_type='ml.t2.large',output_path='s3://{}/{}/output'.format(bucket_name, prefix),sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,eta=0.2,gamma=4,min_child_weight=6,subsample=0.8,silent=0,objective='reg:linear',num_round=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-12 02:43:40 Starting - Starting the training job...\n",
      "2020-10-12 02:43:42 Starting - Launching requested ML instances......\n",
      "2020-10-12 02:44:45 Starting - Preparing the instances for training...\n",
      "2020-10-12 02:45:35 Downloading - Downloading input data...\n",
      "2020-10-12 02:46:11 Training - Downloading the training image...\n",
      "2020-10-12 02:46:31 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-10-12:02:46:31:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-10-12:02:46:31:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[34m[2020-10-12:02:46:31:INFO] File size need to be processed in the node: 195.11mb. Available memory size in the node: 8474.05mb\u001b[0m\n",
      "\u001b[34m[2020-10-12:02:46:31:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[02:46:31] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[02:46:32] 41818x240 matrix with 10036320 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[02:46:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:3.74871\u001b[0m\n",
      "\u001b[34m[02:46:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:3.00901\u001b[0m\n",
      "\u001b[34m[02:46:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:2.41597\u001b[0m\n",
      "\u001b[34m[02:46:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:1.94252\u001b[0m\n",
      "\u001b[34m[02:46:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:1.56157\u001b[0m\n",
      "\u001b[34m[02:46:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:1.25639\u001b[0m\n",
      "\u001b[34m[02:46:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:1.0138\u001b[0m\n",
      "\u001b[34m[02:46:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.819442\u001b[0m\n",
      "\u001b[34m[02:46:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.665778\u001b[0m\n",
      "\u001b[34m[02:46:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.543103\u001b[0m\n",
      "\u001b[34m[02:46:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.446135\u001b[0m\n",
      "\u001b[34m[02:46:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.369528\u001b[0m\n",
      "\u001b[34m[02:46:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.309854\u001b[0m\n",
      "\u001b[34m[02:46:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.264505\u001b[0m\n",
      "\u001b[34m[02:46:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.227456\u001b[0m\n",
      "\u001b[34m[02:46:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.199634\u001b[0m\n",
      "\u001b[34m[02:46:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.176598\u001b[0m\n",
      "\u001b[34m[02:46:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.159655\u001b[0m\n",
      "\u001b[34m[02:46:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.146555\u001b[0m\n",
      "\u001b[34m[02:46:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.13755\u001b[0m\n",
      "\u001b[34m[02:46:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.129501\u001b[0m\n",
      "\u001b[34m[02:46:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.121421\u001b[0m\n",
      "\u001b[34m[02:46:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.116737\u001b[0m\n",
      "\u001b[34m[02:46:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.112521\u001b[0m\n",
      "\u001b[34m[02:46:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.108692\u001b[0m\n",
      "\u001b[34m[02:46:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.105744\u001b[0m\n",
      "\u001b[34m[02:46:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.103665\u001b[0m\n",
      "\u001b[34m[02:46:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.099651\u001b[0m\n",
      "\u001b[34m[02:46:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.097097\u001b[0m\n",
      "\u001b[34m[02:46:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.094377\u001b[0m\n",
      "\u001b[34m[02:46:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 40 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.091906\u001b[0m\n",
      "\u001b[34m[02:46:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 36 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.089588\u001b[0m\n",
      "\u001b[34m[02:46:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 38 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.086671\u001b[0m\n",
      "\u001b[34m[02:46:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.086667\u001b[0m\n",
      "\u001b[34m[02:46:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:0.085169\u001b[0m\n",
      "\u001b[34m[02:46:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 48 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:0.084472\u001b[0m\n",
      "\u001b[34m[02:46:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 24 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:0.083873\u001b[0m\n",
      "\u001b[34m[02:46:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 48 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:0.082538\u001b[0m\n",
      "\u001b[34m[02:46:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:0.082537\u001b[0m\n",
      "\u001b[34m[02:46:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:0.082537\u001b[0m\n",
      "\u001b[34m[02:46:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:0.082537\u001b[0m\n",
      "\u001b[34m[02:46:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:0.082537\u001b[0m\n",
      "\u001b[34m[02:46:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:0.082537\u001b[0m\n",
      "\u001b[34m[02:46:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:0.082537\u001b[0m\n",
      "\u001b[34m[02:46:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:0.082537\u001b[0m\n",
      "\u001b[34m[02:46:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:0.082537\u001b[0m\n",
      "\u001b[34m[02:46:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 48 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:0.081681\u001b[0m\n",
      "\u001b[34m[02:46:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:0.080825\u001b[0m\n",
      "\u001b[34m[02:46:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 28 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:0.080825\u001b[0m\n",
      "\u001b[34m[02:46:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:0.080825\u001b[0m\n",
      "\u001b[34m[02:46:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:0.080825\u001b[0m\n",
      "\u001b[34m[02:46:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:0.080825\u001b[0m\n",
      "\u001b[34m[02:46:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:0.080825\u001b[0m\n",
      "\u001b[34m[02:46:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 28 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[53]#011train-rmse:0.080825\u001b[0m\n",
      "\u001b[34m[02:46:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[54]#011train-rmse:0.080825\u001b[0m\n",
      "\u001b[34m[02:46:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 28 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[55]#011train-rmse:0.080825\u001b[0m\n",
      "\u001b[34m[02:46:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 40 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[56]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[57]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[58]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[59]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[60]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[61]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[62]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[63]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[64]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[66]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 22 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[67]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[68]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[69]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[70]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[71]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[72]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[73]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[74]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[75]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[77]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 28 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[78]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[79]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[80]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[81]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[82]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[83]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[84]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[85]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[86]#011train-rmse:0.079897\u001b[0m\n",
      "\n",
      "2020-10-12 02:47:07 Uploading - Uploading generated training model\u001b[34m[02:46:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[87]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[88]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[89]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[90]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[91]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:46:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[92]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:47:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[93]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:47:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[94]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:47:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[95]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:47:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[96]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:47:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[97]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:47:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[98]#011train-rmse:0.079897\u001b[0m\n",
      "\u001b[34m[02:47:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[99]#011train-rmse:0.079897\u001b[0m\n",
      "\n",
      "2020-10-12 02:47:14 Completed - Training job completed\n",
      "Training seconds: 99\n",
      "Billable seconds: 99\n"
     ]
    }
   ],
   "source": [
    "xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "#Deploy model\n",
    "xgb_predictor = xgb.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Unable to handle input format: ', <class 'int'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-536cda777773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxgb_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'text/csv'\u001b[0m \u001b[0;31m# set the data type for an inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mxgb_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_serializer\u001b[0m \u001b[0;31m# set the serializer type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# predict!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# and turn the prediction into an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \"\"\"\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mrequest_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_request_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36m_create_request_args\u001b[0;34m(self, data, initial_args, target_model, target_variant)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Body\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_mutable_sequence_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_is_sequence_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_CsvSerializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_CsvSerializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_mutable_sequence_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_is_sequence_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_CsvSerializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_CsvSerializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36m_serialize_row\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_csv_serialize_from_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to handle input format: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Unable to handle input format: ', <class 'int'>)"
     ]
    }
   ],
   "source": [
    "xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
    "xgb_predictor.serializer = csv_serializer # set the serializer type\n",
    "predictions = xgb_predictor.predict(test_data).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for array in modelData:\n",
    "    result = linear_predictor.predict(array)\n",
    "    predictions += [r['score'] for r in result['predictions']]\n",
    "predictions = np.array(predictions)\n",
    "# Push into our pandas dataframe\n",
    "data['Predicted'] = predictions.astype(int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
